{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baef2582-4fd1-4837-90e5-d41a67f1e876",
   "metadata": {},
   "source": [
    "# NER Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4c778-063f-4bea-a4ca-d7182afa347e",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899d060b-3b4b-4846-9146-854d529a883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1598f9ae-cc36-415f-a557-cf28f3b383ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kds/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import f1_score as entity_f1_score\n",
    "from sklearn.metrics import f1_score as char_f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, get_scheduler\n",
    "from transformers.adapters import XLMRobertaAdapterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b71f185-5779-4073-bb92-046109fb7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = easydict.EasyDict(\n",
    "    model_name = 'xlm-roberta-base',\n",
    "    batch_size = 32,\n",
    "    num_epochs = 5,\n",
    "    device = 'cuda:2',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150c0b4-d705-48b2-a494-cec1a90cb97f",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a11f92-07b3-4e4b-b584-3a16ea36a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = ' '.join(item['tokens'])\n",
    "        \n",
    "        tags = [] # 각 스펠 단위별로 라벨링을 만드는 리스트 \n",
    "        # 현재 잘려 있는 token과 앞으로 자를 토큰이 다르기 때문에 이걸 해주는 거구나 \n",
    "        for token, tag in zip(item['tokens'], item['ner_tags']):\n",
    "            label = label_list[tag]\n",
    "            tags.append(tag)\n",
    "            for _ in range(len(token)-1): # for문이 끝나고 tags.append(0)을 해주기 때문에 -1을 해줌 \n",
    "                if label[0] == 'B': # token은 여러 글자를 가지고 있고 같은 token이라면 라벨이 B로 시작한다. 그러나, token의 첫번째 글자만 B로 마킹하고자 함 \n",
    "                    tags.append(tag+1)\n",
    "                else:\n",
    "                    tags.append(tag)\n",
    "            tags.append(0)\n",
    "        tags = tags[:-1]\n",
    "        \n",
    "        inputs = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        input_ids = inputs.input_ids[0]\n",
    "        attention_mask = inputs.attention_mask[0]\n",
    "\n",
    "        labels = []\n",
    "        for i in range(self.max_length):\n",
    "            char_span = inputs.token_to_chars(i) # 각 토큰의 시작과 끝을 알려주는 것이기 때문에 max_length 만큼 존재함 \n",
    "            if char_span is None:\n",
    "                label = -100\n",
    "            else:\n",
    "                label = tags[char_span.start]\n",
    "            labels.append(label)\n",
    "            \n",
    "        labels = torch.tensor(labels)\n",
    "        return input_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9074eb-793a-4713-8d7a-f469f508935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b030b6e-dc3e-45d5-a731-a6eaef45f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/kds/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 482.94it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('conll2003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8dbdb8-734a-4ed7-a61d-2cc462ca449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data['train'], tokenizer)\n",
    "valid_dataset = Dataset(data['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d305ea8-39c0-49c9-84cc-e4639683dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ea35d7-47d7-4528-bbac-1400b7a5afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128]), torch.Size([32, 128]), torch.Size([32, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "input_ids, attention_mask, labels = batch\n",
    "input_ids.shape, attention_mask.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df9071-3e32-4a7b-a277-71e9446a3690",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "228ea6f1-4dcb-4947-96ea-4f9412d030f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityHead(nn.Module):\n",
    "    label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "    # 정의 할때는 dropout_porb과 hidden_size가 필요한 것이고 \n",
    "    # 정의한 Entityhead를 사용할 때는 forward에 정의된 변수(hidden_state)가 필요함 \n",
    "    def __init__(self, dropout_prob, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.classifier = nn.Linear(hidden_size, len(self.label_list))\n",
    "    \n",
    "    def forward(self, hidden_state):\n",
    "        hidden_state = self.dropout(hidden_state)\n",
    "        logits = self.classifier(hidden_state)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4f23f8-74ae-4d97-b83f-e47d6da8b7dd",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef6c20ba-bccf-4c55-97e3-93a0481612af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(total_preds, total_labels, label_list):\n",
    "    total_preds_label = [label_list[p] for p in total_preds]\n",
    "    total_labels_label = [label_list[l] for l in total_labels]\n",
    "    \n",
    "    entity_f1 = entity_f1_score([total_labels_label], [total_preds_label], average='macro', mode='strict', scheme=IOB2)\n",
    "    char_f1 = char_f1_score(total_labels, total_preds, labels=list(range(len(label_list)-1)), average='macro', zero_division=True)\n",
    "    \n",
    "    entity_f1 = entity_f1 * 100\n",
    "    char_f1 = char_f1 * 100\n",
    "    return entity_f1, char_f1\n",
    "\n",
    "\n",
    "def evaluate(backbone, head, loader, cfg):\n",
    "    total_preds, total_labels = [], []\n",
    "    for batch in tqdm(loader):\n",
    "        batch = [b.to(cfg.device) for b in batch]\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            hidden_state = backbone(input_ids, attention_mask).last_hidden_state\n",
    "            logits = head(hidden_state)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        preds = preds.flatten().cpu().numpy()\n",
    "        labels = labels.flatten().cpu().numpy()\n",
    "        \n",
    "        for p, l in zip(preds, labels):\n",
    "            if l in [-100, 12]: continue\n",
    "            total_preds.append(p)\n",
    "            total_labels.append(l)\n",
    "    \n",
    "    entity_f1, char_f1 = metric_fn(total_preds, total_labels, head.label_list)\n",
    "    return entity_f1, char_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b178ab61-73fb-4961-ac49-c57a17d5cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaAdapterModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaAdapterModel were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "backbone = XLMRobertaAdapterModel.from_pretrained(cfg.model_name)\n",
    "backbone.add_adapter('entity', overwrite_ok=True) # 똑같은 이름을 가지고 있는 adapter가 있으면 덮어씀 \n",
    "backbone.set_active_adapters('entity')\n",
    "_ = backbone.train().to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836e3f3f-2660-45d1-a247-de6ab6a7ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = EntityHead(backbone.config.hidden_dropout_prob, backbone.config.hidden_size)\n",
    "_ = head.train().to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b269f3-47c4-47da-b245-6f134187b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_params = [param for name, param in backbone.named_parameters() if 'adapter' in name]\n",
    "head_params = list(head.parameters())\n",
    "params = adapter_params + head_params\n",
    "optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f189a51d-5b00-48b6-879f-a6ec5fffd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_training_steps = len(train_loader) * num_epochs\n",
    "num_warmup_steps = int(num_training_steps * 0.1)\n",
    "scheduler = get_scheduler('cosine', optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97676763-69f5-4266-b16d-b34da46db4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:39<00:00,  4.41it/s, loss=0.227]\n",
      "100%|██████████| 102/102 [00:09<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 | entity f1 40.84 | char f1 59.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:43<00:00,  4.23it/s, loss=0.103] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1 | entity f1 80.96 | char f1 88.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:43<00:00,  4.24it/s, loss=0.101] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2 | entity f1 85.58 | char f1 91.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:42<00:00,  4.30it/s, loss=0.0282]\n",
      "100%|██████████| 102/102 [00:09<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3 | entity f1 87.24 | char f1 91.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.31it/s, loss=0.063] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4 | entity f1 87.01 | char f1 92.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.31it/s, loss=0.0619] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5 | entity f1 88.48 | char f1 93.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.30it/s, loss=0.0465] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6 | entity f1 89.03 | char f1 93.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.31it/s, loss=0.072]  \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7 | entity f1 89.85 | char f1 93.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.31it/s, loss=0.0336] \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8 | entity f1 89.53 | char f1 93.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [01:41<00:00,  4.31it/s, loss=0.115]  \n",
      "100%|██████████| 102/102 [00:09<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9 | entity f1 89.58 | char f1 93.95\n"
     ]
    }
   ],
   "source": [
    "for ep in range(num_epochs):\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        batch = [b.to(cfg.device) for b in batch]\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        \n",
    "        hidden_state = backbone(input_ids, attention_mask).last_hidden_state\n",
    "        logits = head(hidden_state) \n",
    "        \n",
    "        # b : batch_size \n",
    "        # s : sequence의 줄임말로 max_length 만큼 출력됨 \n",
    "        # c : label list에 있는 것들이 각각의 일어날 확률을 말하는 거구나?\n",
    "        # 다른 곳에서는 이렇게 rearange를 안해주는데 왜 여기서만 해주는거지?\n",
    "        logits = rearrange(logits, 'b s c -> (b s) c') # logits : torch.Size([32, 128, 9]) -> logits : (torch.Size([4096, 9]) == (batch_size, number of class)\n",
    "        # tensor의 rearrange를 하는 이유는 간단하다. 연산을 간변하게 하기 위해서 이다. \n",
    "        # [32, 128, ?] -> [4096, ?]로 변경된 것은 32개의 [128, 9]의 행렬을 하나로 합쳐놓은 거라고 생각하면 된다. \n",
    "        # 이해가 되지 않으면 torch.randn(2, 3, 5)를 활용하여 간단하게 계산해보기 바란다. \n",
    "        labels = rearrange(labels, 'b s -> (b s)') #  labels : torch.Size([32, 128] -> labels : torch.Size([4096])\n",
    "        loss = F.cross_entropy(logits, labels) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    entity_f1, char_f1 = evaluate(backbone, head, valid_loader, cfg)\n",
    "    print(f'ep {ep:01d} | entity f1 {entity_f1:.2f} | char f1 {char_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc13e37-f80d-4d30-8a19-2e00a6347335",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.save_adapter('models/adapters/entity', 'entity')\n",
    "torch.save(head.state_dict(), 'models/heads/entity.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb9ac7-8c4c-41b7-ad4c-9c5b54ba7586",
   "metadata": {},
   "source": [
    "## 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fad2b-da9a-4145-89f2-2560340bfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "# from adapter_transformers.src.transformers.adapters import XLMRobertaAdapterModel\n",
    "from transformers.adapters import XLMRobertaAdapterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5261b0-3699-4629-b763-9779266deae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = easydict.EasyDict(\n",
    "    model_name = 'xlm-roberta-base',\n",
    "    device = 'cuda:2',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4c628-a7f8-40b4-80ab-1bff71da523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(inputs, logits, label_list):\n",
    "    num_texts = logits.size(0) # logits size : torch.Size([1, 문장길이, 9]) 9는 분류하고자하는 라벨의 종류 수 \n",
    "    input_ids = inputs.input_ids.cpu().numpy()\n",
    "    \n",
    "    scores = logits.softmax(dim=-1)\n",
    "    scores, preds = scores.max(dim=-1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    scores = scores.cpu().numpy()\n",
    "    \"\"\"\n",
    "    preds : [[0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 4 0 0 0 0 3 4 4 0 0 0 0 3\n",
    "              4 4 0 3 4 0 0 0 0 3 4 4 4 0 3 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
    "    scores : [[0.33479157 0.46193483 0.98810464 0.8788983  0.7549816  0.66784626\n",
    "                0.40162045 0.51870275 0.84481525 0.99972934 0.9996375  0.99967337\n",
    "                0.9997254  0.99979717 0.99983394 0.99981886 0.9997837  0.99967706\n",
    "                0.99987686 0.9998398  0.9996594  0.99090004 0.9956403  0.9963806\n",
    "                0.9998048  0.9996369  0.99984634 0.9990269  0.99177706 0.99515235\n",
    "                0.9960179  0.99981445 0.9995647  0.9998305  0.9994886  0.99170285\n",
    "                0.99539775 0.99576026 0.9765133  0.9661636  0.9937236  0.9618989\n",
    "                0.9997024  0.9995864  0.9995679  0.98423475 0.9917414  0.9933913\n",
    "                0.9942795  0.97152    0.97173023 0.9844504  0.9859282  0.93398285\n",
    "                0.99957556 0.99927396 0.99951065 0.99959224 0.9973635  0.99931073\n",
    "                0.9998578  0.99954706 0.9965514  0.99979395 0.9997625  0.9998196\n",
    "                0.99960154 0.9995741  0.999689   0.9994893  0.34495312]]\n",
    "    \"\"\"\n",
    "\n",
    "    total_spans = []\n",
    "    for i in range(num_texts):\n",
    "        pred = preds[i]\n",
    "        pred = [label_list[p] for p in pred]\n",
    "        \n",
    "        spans, buffer = [], []\n",
    "        for j, p in enumerate(pred):\n",
    "            if p[0] == 'B':\n",
    "                if input_ids[i, j] == 6: continue # 6은 ''를 가르킴 \n",
    "                if buffer: # 빈리스트가 아닐때를 의미함 \n",
    "                    spans.append(buffer)\n",
    "                    buffer = []\n",
    "                \n",
    "                # batch_size가 1일때는 inputs.token_to_chars이라고 하면되는데 \n",
    "                # batch_size가 1 이상일 때는 앞에 batch_index, token_index 순으로 넣어주어야합니다. \n",
    "                # 그래서 아래는 i, j라는 구조로 입력이 들어가게 되는 것입니다. \n",
    "                start, end = inputs.token_to_chars(i, j)\n",
    "                buffer.append({'entity': p[-2:], 'start': start, 'end': end, 'score': scores[i,j]})\n",
    "\n",
    "        \n",
    "            elif p[0] == 'I':\n",
    "                if not buffer: continue      \n",
    "                start, end = inputs.token_to_chars(i, j)\n",
    "                buffer.append({'entity': p[-2:], 'start': start, 'end': end, 'score': scores[i,j]})\n",
    "\n",
    "\n",
    "            elif p[0] == 'O':\n",
    "                if not buffer: continue\n",
    "                spans.append(buffer)\n",
    "                buffer = []\n",
    "                    \n",
    "        total_spans.append(spans)\n",
    "    return total_spans\n",
    "\n",
    "\n",
    "def grouping(span, text):\n",
    "    start = span[0]['start']\n",
    "    end = span[-1]['end']\n",
    "    word = text[start:end]\n",
    "    entity = span[0]['entity']\n",
    "    score = np.prod([s['score'] for s in span])\n",
    "    return {\n",
    "        'word': word,\n",
    "        'entity': entity,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(backbone, head, tokenizer, texts):\n",
    "    inputs = tokenizer(texts, padding=True, return_tensors='pt').to(cfg.device)\n",
    "\n",
    "    hidden_state = backbone(**inputs).last_hidden_state\n",
    "    logits = head(hidden_state)\n",
    "    \n",
    "    total_spans = postprocess(inputs, logits, head.label_list)\n",
    "    total_groups = []\n",
    "    for spans, text in zip(total_spans, texts):\n",
    "        groups = [grouping(span, text) for span in spans]\n",
    "        total_groups.append(groups)\n",
    "        \n",
    "    return total_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73e439-0fa9-496e-950a-535ad516d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7d792-31f0-4eb2-b919-4900c8cbdeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = XLMRobertaAdapterModel.from_pretrained(cfg.model_name)\n",
    "backbone.load_adapter('models/adapters/entity')\n",
    "_ = backbone.eval().requires_grad_(False).to(cfg.device)\n",
    "backbone.set_active_adapters('entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee9ca5f-c507-4b67-b31c-95b1a5ef2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = EntityHead(backbone.config.hidden_dropout_prob, backbone.config.hidden_size)\n",
    "head.load_state_dict(torch.load('models/heads/entity.pt'))\n",
    "_ = head.eval().requires_grad_(False).to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c953d-bb6b-4e7a-b937-818f728cd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    '국제 신용평가사 피치가 내년 성장률을 1.9%로 전망한 것을 시작으로 한국경제연구원(1.9%), 한국금융연구원(1.7%), 한국개발연구원(KDI·1.8%), 경제협력개발기구(OECD·1.8%) 등 주요 기관들은 줄줄이 1%대로 낮춰잡았다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a2571-30d1-4cd4-b7fe-192f2e804624",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(backbone, head, tokenizer, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b33cc-bcb5-4793-aef9-d589650659fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'word': '한국경제연구원',\n",
       "   'entity': 'RG',\n",
       "   'start': 39,\n",
       "   'end': 46,\n",
       "   'score': 0.9830092},\n",
       "  {'word': '한국금융연구원',\n",
       "   'entity': 'RG',\n",
       "   'start': 54,\n",
       "   'end': 61,\n",
       "   'score': 0.9830391},\n",
       "  {'word': '한국개발연구원',\n",
       "   'entity': 'RG',\n",
       "   'start': 69,\n",
       "   'end': 76,\n",
       "   'score': 0.9829536},\n",
       "  {'word': 'KDI', 'entity': 'RG', 'start': 77, 'end': 80, 'score': 0.9600995},\n",
       "  {'word': '경제협력개발기구',\n",
       "   'entity': 'RG',\n",
       "   'start': 88,\n",
       "   'end': 96,\n",
       "   'score': 0.9641086},\n",
       "  {'word': 'OECD',\n",
       "   'entity': 'RG',\n",
       "   'start': 97,\n",
       "   'end': 101,\n",
       "   'score': 0.9431588}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d85ba7-4cd6-4671-9f8f-b997624f14bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e2d7ca79a99b4d5a707dfaab981df2b9540e7e1fc99e04bbfd99d05b5364505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
